
@unpublished{simardMachineTeachingNew2017,
  title = {Machine {{Teaching}}: {{A New Paradigm}} for {{Building Machine Learning Systems}}},
  shorttitle = {Machine {{Teaching}}},
  author = {Simard, Patrice Y. and Amershi, Saleema and Chickering, David M. and Pelton, Alicia Edelman and Ghorashi, Soroush and Meek, Christopher and Ramos, Gonzalo and Suh, Jina and Verwey, Johan and Wang, Mo and Wernsing, John},
  date = {2017-08-10},
  eprint = {1707.06742},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1707.06742},
  url = {http://arxiv.org/abs/1707.06742},
  urldate = {2022-04-13},
  abstract = {The current processes for building machine learning systems require practitioners with deep knowledge of machine learning. This significantly limits the number of machine learning systems that can be created and has led to a mismatch between the demand for machine learning systems and the ability for organizations to build them. We believe that in order to meet this growing demand for machine learning systems we must significantly increase the number of individuals that can teach machines. We postulate that we can achieve this goal by making the process of teaching machines easy, fast and above all, universally accessible. While machine learning focuses on creating new algorithms and improving the accuracy of "learners", the machine teaching discipline focuses on the efficacy of the "teachers". Machine teaching as a discipline is a paradigm shift that follows and extends principles of software engineering and programming languages. We put a strong emphasis on the teacher and the teacher's interaction with data, as well as crucial components such as techniques and design principles of interaction and visualization. In this paper, we present our position regarding the discipline of machine teaching and articulate fundamental machine teaching principles. We also describe how, by decoupling knowledge about machine learning algorithms from the process of teaching, we can accelerate innovation and empower millions of new uses for machine learning models.},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Human-Computer Interaction,Computer Science - Machine Learning,Computer Science - Software Engineering,important,philosophy,Statistics - Machine Learning}
}


@article{dudleyReviewUserInterface2018,
  title = {A {{Review}} of {{User Interface Design}} for {{Interactive Machine Learning}}},
  author = {Dudley, John J. and Kristensson, Per Ola},
  date = {2018-06-13},
  journaltitle = {ACM Transactions on Interactive Intelligent Systems},
  shortjournal = {ACM Trans. Interact. Intell. Syst.},
  volume = {8},
  number = {2},
  pages = {8:1--8:37},
  issn = {2160-6455},
  doi = {10.1145/3185517},
  url = {https://doi.org/10.1145/3185517},
  urldate = {2022-04-14},
  abstract = {Interactive Machine Learning (IML) seeks to complement human perception and intelligence by tightly integrating these strengths with the computational power and speed of computers. The interactive process is designed to involve input from the user but does not require the background knowledge or experience that might be necessary to work with more traditional machine learning techniques. Under the IML process, non-experts can apply their domain knowledge and insight over otherwise unwieldy datasets to find patterns of interest or develop complex data-driven applications. This process is co-adaptive in nature and relies on careful management of the interaction between human and machine. User interface design is fundamental to the success of this approach, yet there is a lack of consolidated principles on how such an interface should be implemented. This article presents a detailed review and characterisation of Interactive Machine Learning from an interactive systems perspective. We propose and describe a structural and behavioural model of a generalised IML system and identify solution principles for building effective interfaces for IML. Where possible, these emergent solution principles are contextualised by reference to the broader human-computer interaction literature. Finally, we identify strands of user interface research key to unlocking more efficient and productive non-expert interactive machine learning applications.},
  keywords = {important,Interactive machine learning,interface design,toread}
}

@inproceedings{laiScienceHumanAIDecision2023,
  title = {Towards a {{Science}} of {{Human-AI Decision Making}}: {{An Overview}} of {{Design Space}} in {{Empirical Human-Subject Studies}}},
  shorttitle = {Towards a {{Science}} of {{Human-AI Decision Making}}},
  booktitle = {2023 {{ACM Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  author = {Lai, Vivian and Chen, Chacha and Smith-Renner, Alison and Liao, Q. Vera and Tan, Chenhao},
  date = {2023-06-12},
  pages = {1369--1385},
  publisher = {{ACM}},
  location = {{Chicago IL USA}},
  doi = {10.1145/3593013.3594087},
  url = {https://dl.acm.org/doi/10.1145/3593013.3594087},
  urldate = {2023-06-22},
  abstract = {AI systems are adopted in numerous domains due to their increasingly strong predictive performance. However, in high-stakes domains such as criminal justice and healthcare, full automation is often not desirable due to safety, ethical, and legal concerns, yet fully manual approaches can be inaccurate and time-consuming. As a result, there is growing interest in the research community to augment human decision making with AI assistance. Besides developing AI technologies for this purpose, the emerging field of human-AI decision making must embrace empirical approaches to form a foundational understanding of how humans interact and work with AI to make decisions. To invite and help structure research efforts towards a science of understanding and improving human-AI decision making, we survey recent literature of empirical human-subject studies on this topic. We summarize the study design choices made in over 100 papers in three important aspects: (1) decision tasks, (2) AI assistance elements, and (3) evaluation metrics. For each aspect, we summarize current trends, discuss gaps in current practices of the field, and make a list of recommendations for future research. Our work highlights the need to develop common frameworks to account for the design and research spaces of human-AI decision making, so that researchers can make rigorous choices in study design, and the research community can build on each other’s work and produce generalizable scientific knowledge. We also hope this work will serve as a bridge for HCI and AI communities to work together to mutually shape the empirical science and computational technologies for human-AI decision making.},
  eventtitle = {{{FAccT}} '23: The 2023 {{ACM Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  isbn = {9798400701924},
  langid = {english},
  keywords = {important}
}

@article{amershiPowerPeopleRole2014,
  title = {Power to the {{People}}: {{The Role}} of {{Humans}} in {{Interactive Machine Learning}}},
  shorttitle = {Power to the {{People}}},
  author = {Amershi, Saleema and Cakmak, Maya and Knox, William Bradley and Kulesza, Todd},
  date = {2014-12-22},
  journaltitle = {AI Magazine},
  volume = {35},
  number = {4},
  pages = {105--120},
  issn = {2371-9621},
  doi = {10.1609/aimag.v35i4.2513},
  url = {https://ojs.aaai.org/index.php/aimagazine/article/view/2513},
  urldate = {2022-04-14},
  abstract = {Intelligent systems that learn interactively from their end-users are quickly becoming widespread. Until recently, this progress has been fueled mostly by advances in machine learning; however, more and more researchers are realizing the importance of studying users of these systems. In this article we promote this approach and demonstrate how it can result in better user experiences and more effective learning systems. We present a number of case studies that characterize the impact of interactivity, demonstrate ways in which some existing systems fail to account for the user, and explore new ways for learning systems to interact with their users. We argue that the design process for interactive machine learning systems should involve users at all stages: explorations that reveal human interaction patterns and inspire novel interaction methods, as well as refinement stages to tune details of the interface and choose among alternatives. After giving a glimpse of the progress that has been made so far, we discuss the challenges that we face in moving the field forward.},
  issue = {4},
  langid = {english},
  keywords = {Interactive Machine Learning,toread}
}

@article{cakmakDesigningInteractionsRobot2010,
  title = {Designing {{Interactions}} for {{Robot Active Learners}}},
  author = {Cakmak, Maya and Chao, Crystal and Thomaz, Andrea L.},
  date = {2010-06},
  journaltitle = {IEEE Transactions on Autonomous Mental Development},
  volume = {2},
  number = {2},
  pages = {108--118},
  issn = {1943-0612},
  doi = {10.1109/TAMD.2010.2051030},
  abstract = {This paper addresses some of the problems that arise when applying active learning to the context of human-robot interaction (HRI). Active learning is an attractive strategy for robot learners because it has the potential to improve the accuracy and the speed of learning, but it can cause issues from an interaction perspective. Here we present three interaction modes that enable a robot to use active learning queries. The three modes differ in when they make queries: the first makes a query every turn, the second makes a query only under certain conditions, and the third makes a query only when explicitly requested by the teacher. We conduct an experiment in which 24 human subjects teach concepts to our upper-torso humanoid robot, Simon, in each interaction mode, and we compare these modes against a baseline mode using only passive supervised learning. We report results from both a learning and an interaction perspective. The data show that the three modes using active learning are preferable to the mode using passive supervised learning both in terms of performance and human subject preference, but each mode has advantages and disadvantages. Based on our results, we lay out several guidelines that can inform the design of future robotic systems that use active learning in an HRI setting.},
  eventtitle = {{{IEEE Transactions}} on {{Autonomous Mental Development}}},
  keywords = {Active learning,Chaos,Educational robots,Guidelines,Human robot interaction,human–robot interaction,Humanoid robots,Intelligent robots,Learning systems,Machine learning,Orbital robotics,Supervised learning}
}

@article{suhAnchorVizFacilitatingSemantic2019,
  title = {{{AnchorViz}}: {{Facilitating Semantic Data Exploration}} and {{Concept Discovery}} for {{Interactive Machine Learning}}},
  shorttitle = {{{AnchorViz}}},
  author = {Suh, Jina and Ghorashi, Soroush and Ramos, Gonzalo and Chen, Nan-Chen and Drucker, Steven and Verwey, Johan and Simard, Patrice},
  date = {2019-08-09},
  journaltitle = {ACM Transactions on Interactive Intelligent Systems},
  shortjournal = {ACM Trans. Interact. Intell. Syst.},
  volume = {10},
  number = {1},
  pages = {7:1--7:38},
  issn = {2160-6455},
  doi = {10.1145/3241379},
  url = {https://doi.org/10.1145/3241379},
  urldate = {2022-04-13},
  abstract = {When building a classifier in interactive machine learning (iML), human knowledge about the target class can be a powerful reference to make the classifier robust to unseen items. The main challenge lies in finding unlabeled items that can either help discover or refine concepts for which the current classifier has no corresponding features (i.e., it has feature blindness). Yet it is unrealistic to ask humans to come up with an exhaustive list of items, especially for rare concepts that are hard to recall. This article presents AnchorViz, an interactive visualization that facilitates the discovery of prediction errors and previously unseen concepts through human-driven semantic data exploration. By creating example-based or dictionary-based anchors representing concepts, users create a topology that (a) spreads data based on their similarity to the concepts and (b) surfaces the prediction and label inconsistencies between data points that are semantically related. Once such inconsistencies and errors are discovered, users can encode the new information as labels or features and interact with the retrained classifier to validate their actions in an iterative loop. We evaluated AnchorViz through two user studies. Our results show that AnchorViz helps users discover more prediction errors than stratified random and uncertainty sampling methods. Furthermore, during the beginning stages of a training task, an iML tool with AnchorViz can help users build classifiers comparable to the ones built with the same tool with uncertainty sampling and keyword search, but with fewer labels and more generalizable features. We discuss exploration strategies observed during the two studies and how AnchorViz supports discovering, labeling, and refining of concepts through a sensemaking loop.},
  keywords = {concept discovery,error discovery,important,Interactive machine learning,machine teaching,semantic data exploration,unlabeled data,visualization}
}


@misc{panelholoviz,
title={Panel: The powerful data exploration \& web app framework for {P}ython},
author={Holoviz},
doi = {10.5281/zenodo.3706648},
howpublished={\url{https://panel.holoviz.org/}},
year={2018},
note={Accessed: 2023-10-10},
}

@misc{ipyvuetify,
title={ipyvuetify: Jupyter widgets based on vuetify UI components},
author={Widgetti},
howpublished={\url{https://github.com/widgetti/ipyvuetify}},
year={2019},
note={Accessed: 2023-10-12},
}

@article{scikit-learn,
 title={Scikit-learn: Machine Learning in {P}ython},
 author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
 doi = {10.48550/arXiv.1201.0490},
 journal={Journal of Machine Learning Research},
 volume={12},
 pages={2825--2830},
 year={2011}
}

@inproceedings{failsInteractiveMachineLearning,
author = {Fails, Jerry Alan and Olsen, Dan R.},
title = {Interactive Machine Learning},
year = {2003},
isbn = {1581135866},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/604045.604056},
doi = {10.1145/604045.604056},
abstract = {Perceptual user interfaces (PUIs) are an important part of ubiquitous computing. Creating such interfaces is difficult because of the image and signal processing knowledge required for creating classifiers. We propose an interactive machine-learning (IML) model that allows users to train, classify/view and correct the classifications. The concept and implementation details of IML are discussed and contrasted with classical machine learning models. Evaluations of two algorithms are also presented. We also briefly describe Image Processing with Crayons (Crayons), which is a tool for creating new camera-based interfaces using a simple painting metaphor. The Crayons tool embodies our notions of interactive machine learning},
booktitle = {Proceedings of the 8th International Conference on Intelligent User Interfaces},
pages = {39–45},
numpages = {7},
keywords = {machine learning, image processing, perceptive user interfaces, interaction, classification},
location = {Miami, Florida, USA},
series = {IUI '03}
}
